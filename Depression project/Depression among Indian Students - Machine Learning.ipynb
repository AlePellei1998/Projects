{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling depression using Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1: can depression be predicted based on X,Y,Z?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3: what are the students that need the highest help? How can we help them? What exists in India to prevent this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_val_predict\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SequentialFeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 8) \n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender                 True\n",
       "Age                   False\n",
       "City                   True\n",
       "Academic Pressure     False\n",
       "CGPA                  False\n",
       "Study Satisfaction    False\n",
       "Sleep Duration         True\n",
       "Dietary Habits         True\n",
       "Degree                 True\n",
       "Suicidal Thoughts      True\n",
       "Work_study_hours      False\n",
       "Financial Stress      False\n",
       "Family History         True\n",
       "Depression            False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"depression_after_eda.csv\")\n",
    "df.applymap(type).eq(str).any() #to check which column in the dataset contains string values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "#for now we take out degree and cities, because harder to factorise and not sure if very relevant\n",
    "print(df[\"Degree\"].nunique())\n",
    "print(df[\"City\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I exclude City and Degree for now\n",
    "X = df[[\"Gender\",\"Age\",\"Academic Pressure\",\"CGPA\",\"Study Satisfaction\", \"Sleep Duration\",\"Dietary Habits\",\"Suicidal Thoughts\", \"Work_study_hours\",\"Financial Stress\", \"Family History\"]]\n",
    "y = df[\"Depression\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depression\n",
      "1    0.585499\n",
      "0    0.414501\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#the two classes do not seem imbalances\n",
    "print(y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-634a1fa28c87>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[\"Gender\"]=X[\"Gender\"].map({\"Male\":0,\"Female\":1})\n",
      "<ipython-input-10-634a1fa28c87>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[\"Sleep Duration\"]=X[\"Sleep Duration\"].factorize()[0] #to simplify with categories\n",
      "<ipython-input-10-634a1fa28c87>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[\"Dietary Habits\"]=X[\"Dietary Habits\"].factorize()[0]\n",
      "<ipython-input-10-634a1fa28c87>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[\"Suicidal Thoughts\"]=X[\"Suicidal Thoughts\"].map({\"Yes\":1,\"No\":0})\n",
      "<ipython-input-10-634a1fa28c87>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[\"Family History\"]=X[\"Family History\"].map({\"Yes\":1,\"No\":0})\n"
     ]
    }
   ],
   "source": [
    "#I first create numerical categories for all non-numerical features I want to retain: \n",
    "#Gender, Sleep Duration, Dietary Habits, Suicidal Thoughts, Family History\n",
    "X[\"Gender\"]=X[\"Gender\"].map({\"Male\":0,\"Female\":1})\n",
    "X[\"Sleep Duration\"]=X[\"Sleep Duration\"].factorize()[0] #to simplify with categories\n",
    "X[\"Dietary Habits\"]=X[\"Dietary Habits\"].factorize()[0]\n",
    "X[\"Suicidal Thoughts\"]=X[\"Suicidal Thoughts\"].map({\"Yes\":1,\"No\":0})\n",
    "X[\"Family History\"]=X[\"Family History\"].map({\"Yes\":1,\"No\":0})\n",
    "\n",
    "# I then perform a one-hot encoding on the categorical variables I factorised.\n",
    "X = pd.get_dummies(columns=[\"Gender\", \"Sleep Duration\", \"Dietary Habits\", \"Suicidal Thoughts\", \"Family History\"], drop_first=True, data=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st hold-out technique: train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=52, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I define the following pipeline with StandardScaler and KNeighborsClassifier:\n",
    "#1-StandardScaler standardizes our data by subtracting the mean from each feature and dividing by its standard deviation. \n",
    "#Scaling features is important given that Euclidean distance is used to compute the number of KNN\n",
    "\n",
    "#When I call a pipeline the following happens under the hood automatically:\n",
    "#StandardScaler().fit(X_train) — learns the mean and std from the training data\n",
    "#StandardScaler().transform(X_train) — scales X_train using those parameters\n",
    "#KNeighborsClassifier().fit(...) — trains on the scaled X_train\n",
    "pipeline = Pipeline([('scaler', StandardScaler()), ('knn', KNeighborsClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuning the model to understand when the testing error is minimised\n",
    "k_range=list(range(1,101))\n",
    "training_error=[]\n",
    "testing_error=[]\n",
    "\n",
    "for k in k_range:\n",
    "    pipeline = Pipeline([('scaler', StandardScaler()), ('knn', KNeighborsClassifier(k))])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_class = pipeline.predict(X_test)\n",
    "    testing_accuracy=metrics.accuracy_score(y_test, y_pred_class)\n",
    "    testing_error.append(1-testing_accuracy)\n",
    "    \n",
    "    y_pred_class = pipeline.predict(X_train)\n",
    "    training_accuracy=metrics.accuracy_score(y_train, y_pred_class)\n",
    "    training_error.append(1-training_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#k=12 is the value that minimises the testing error\n",
    "knn_error = pd.DataFrame(list(zip(k_range, training_error, testing_error)), columns=[\"k\",\"training_error\",\"testing_error\"])\n",
    "knn_error.set_index(\"k\").sort_values(by=\"testing_error\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_error.set_index(\"k\").sort_values(by=\"testing_error\", ascending=True).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing the accuracy with k=94\n",
    "pipeline_knn = Pipeline([('scaler', StandardScaler()), ('knn', KNeighborsClassifier(94))])\n",
    "pipeline_knn.fit(X_train, y_train)\n",
    "y_pred_knn=pipeline_knn.predict(X_test)\n",
    "print(f' The accuracy of the KNN model is: {metrics.accuracy_score(y_test, y_pred_knn):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy of the null model (most frequent class)\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "dummy_clf.predict(X_test)\n",
    "print(f'The accuracy of the null model is: {dummy_clf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix\n",
    "class_names = ['depressed_no', 'depressed_yes']\n",
    "ConfusionMatrixDisplay.from_estimator(pipeline.fit(X_train, y_train), X_test, y_test,\n",
    "                                 display_labels=class_names, cmap=plt.cm.Blues);\n",
    "plt.savefig(\"Confusion matrix from KNN\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#classification report\n",
    "print(metrics.classification_report(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the model is very good at ranking the positive cases (e.g. “depressed”) \n",
    "#higher than the negative cases (e.g. “not depressed”)\n",
    "RocCurveDisplay.from_estimator(pipeline_knn, X_test, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test[\"y_pred_knn\"] = y_pred_knn\n",
    "X_test[\"y\"]=df.loc[X_test.index, \"Depression\"]\n",
    "X_test[\"y_pred=y\"] = X_test[\"y_pred_knn\"] == X_test[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#accuracy of the model\n",
    "X_test[\"y_pred=y\"].value_counts(normalize=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#investigating false negative\n",
    "false_negatives_knn=X_test[(X_test[\"y_pred_knn\"]==0)&(X_test[\"y\"]==1)]\n",
    "false_negatives_knn.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "true_positives = X_test[(X_test[\"y_pred_knn\"]==1)&(X_test[\"y\"]==1)]\n",
    "true_positives.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#comparing histograms between FN and TP\n",
    "columns = [\"Age\", \"Academic Pressure\", \"CGPA\", \"Study Satisfaction\", \"Work_study_hours\", \"Financial Stress\"]\n",
    "for column in columns:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.hist(false_negatives_knn[column], bins=20, alpha=0.5, label='False Negatives', edgecolor=\"red\", linewidth=2, histtype='step', fill=False, density=True)\n",
    "    plt.hist(true_positives[column], bins=20, alpha=0.5, label='True Positives', edgecolor=\"green\", linewidth=2, histtype='step', fill=False,  density=True)\n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Differences are driven by 1) age, 2)academic pressure, 3)study satisfaction, 4)financial stress.\n",
    "# 1) true positives are younger, whereas false negatives are in general older;\n",
    "# 2) true positives have a right-skewed distribution (more people feeling higher academic pressure)\n",
    "# 3) true positives have a left-skewed distribution (less and less people feeling higher study satisfaction).\n",
    "# 4) TP have a right-skewed distribution vs FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#True negatives and false positives\n",
    "true_negatives_knn = X_test[(X_test[\"y_pred_knn\"]==0)&(X_test[\"y\"]==1)]\n",
    "false_positives_knn = X_test[(X_test[\"y_pred_knn\"]==1)&(X_test[\"y\"]==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"Age\", \"Academic Pressure\", \"CGPA\", \"Study Satisfaction\", \"Work_study_hours\", \"Financial Stress\"]\n",
    "for column in columns:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.hist(true_negatives_knn[column], bins=20, alpha=0.5, label='True Negative', edgecolor=\"blue\", linewidth=2, histtype='step', fill=False, density=True)\n",
    "    plt.hist(false_positives_knn[column], bins=20, alpha=0.5, label='False Positives', edgecolor=\"orange\", linewidth=2, histtype='step', fill=False,  density=True)\n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2nd hold-out technique: cross-validation:\n",
    "#I average the five accuracy values I get for each fold)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=2023) #randomly shuffling the data\n",
    "scores=cross_val_score(pipeline, X, y, cv=kf, scoring='accuracy')\n",
    "print(f'The accuracy of the model using cross-validation is: {np.mean(scores):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cross_val = cross_val_predict(pipeline, X, y, cv=kf)\n",
    "cm = confusion_matrix(y, y_pred_cross_val)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(\"Confusion Matrix from Cross-Validation\")\n",
    "plt.show()\n",
    "\n",
    "#this makes predictions for all samples, so 100% ofb the data, unlike train/test split\n",
    "#which only focuses on test data.\n",
    "\n",
    "#there are a lot of false positives - the model predicts that 3081 students are depressed while in fact they are not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#adding degrees and cities will increase accuracy?\n",
    "X = df[[\"Gender\",\"City\",\"Degree\",\"Age\",\"Academic Pressure\",\"CGPA\",\"Study Satisfaction\", \"Sleep Duration\",\"Dietary Habits\",\"Suicidal Thoughts\", \"Work_study_hours\",\"Financial Stress\", \"Family History\"]]\n",
    "X[\"City\"] = X[\"City\"].factorize()[0]\n",
    "X[\"Degree\"] = X[\"Degree\"].factorize()[0]\n",
    "X = pd.get_dummies(columns=[\"Gender\", \"City\",\"Degree\",\"Sleep Duration\", \"Dietary Habits\", \"Suicidal Thoughts\", \"Family History\"], drop_first=True, data=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding Degree and City reduces my accuracy\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=52, stratify=y)\n",
    "pipeline_knn = Pipeline([('scaler', StandardScaler()), ('knn', KNeighborsClassifier(94))])\n",
    "pipeline_knn.fit(X_train, y_train)\n",
    "y_pred_knn=pipeline_knn.predict(X_test)\n",
    "print(f' The accuracy of the KNN model is: {metrics.accuracy_score(y_test, y_pred_knn):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to check the best variable combination\n",
    "\n",
    "# Recreate your full pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=94))\n",
    "])\n",
    "\n",
    "# Use forward selection to add features one at a time\n",
    "sfs = SequentialFeatureSelector(pipeline, n_features_to_select='auto', direction='forward', scoring='accuracy', cv=5, n_jobs=-1)\n",
    "\n",
    "sfs.fit(X, y)\n",
    "\n",
    "# See which features were selected\n",
    "selected_features = X.columns[sfs.get_support()]\n",
    "print(\"Best feature combination:\", list(selected_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy improves a bit more - from 0.839 to 0.845\n",
    "X = df[[\"Age\",\"Academic Pressure\",\"Study Satisfaction\",\"Dietary Habits\",\"Suicidal Thoughts\", \"Work_study_hours\",\"Financial Stress\"]]\n",
    "X[\"Dietary Habits\"]=X[\"Dietary Habits\"].factorize()[0]\n",
    "X[\"Suicidal Thoughts\"]=X[\"Suicidal Thoughts\"].map({\"Yes\":1,\"No\":0})\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=52, stratify=y)\n",
    "pipeline_knn = Pipeline([('scaler', StandardScaler()), ('knn', KNeighborsClassifier(94))])\n",
    "pipeline_knn.fit(X_train, y_train)\n",
    "y_pred_knn=pipeline_knn.predict(X_test)\n",
    "print(f' The accuracy of the KNN model is: {metrics.accuracy_score(y_test, y_pred_knn):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "It seems to outperform KNN, as accuracy here is 83%!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_logreg = Pipeline([('scaler', StandardScaler()), ('logreg', LogisticRegression())])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=51)\n",
    "pipeline_logreg.fit(X_train, y_train)\n",
    "y_pred_logreg = pipeline_logreg.predict(X_test)\n",
    "pipeline_logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class_names = ['depressed_no', 'depressed_yes']\n",
    "ConfusionMatrixDisplay.from_estimator(pipeline_logreg, X_test, y_test,\n",
    "                                 display_labels=class_names,\n",
    "                                 cmap=\"Reds\");\n",
    "plt.title(\"Confusion Matrix\");\n",
    "plt.savefig(\"Confusion Matrix from logistic regression\", dpi=300, bbox_inches=\"tight\");\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics.RocCurveDisplay.from_estimator(pipeline_logreg, X_test, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test[\"y_pred_logreg\"]=y_pred_logreg\n",
    "X['y_pred_probabilities'] = pipeline_logreg.predict_proba(X)[:, 1]\n",
    "#X_test[\"y\"]=df.loc[X_test.index, \"Depression\"]\n",
    "#X_test[\"y_pred_logreg = y\"] = X_test[\"y_pred_logreg\"] == X_test[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#I get higher accuracy if I don't scale the data -> fewer true negatives but more true positives.\n",
    "logreg = LogisticRegression()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_logreg = logreg.predict(X_test)\n",
    "print(logreg.score(X_test, y_test))\n",
    "print(confusion_matrix(y_test, y_pred_logreg))\n",
    "\n",
    "#this is interesting, I get 0.85 accuracy. BUT WHY WHEN I SCALE THE DATA I GET A SLIGHTLY LOWER ACCURACY? \n",
    "#TO BE INVESTIGATED FURTHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg1=LogisticRegression(penalty='none', solver='lbfgs')  # if no scaling\n",
    "logreg2=LogisticRegression(penalty='l2', solver='lbfgs') #if scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "logreg1.fit(X_train, y_train)\n",
    "y_pred_logreg1 = logreg1.predict(X_test)\n",
    "print(logreg1.score(X_test, y_test))\n",
    "print(confusion_matrix(y_test, y_pred_logreg1))\n",
    "\n",
    "np.mean(cross_val_score(logreg1, X, y, cv=5, scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "logreg2.fit(X_train, y_train)\n",
    "y_pred_logreg2 = logreg2.predict(X_test)\n",
    "print(logreg2.score(X_test, y_test))\n",
    "print(confusion_matrix(y_test, y_pred_logreg2))\n",
    "\n",
    "np.mean(cross_val_score(logreg2, X, y, cv=5, scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred_logreg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Decision Tree is a supervised machine learning algorithm used for both classification and regression tasks. It models decisions and their possible consequences as a tree-like structure of if-then-else conditions, helping the algorithm learn patterns in the data to make predictions.\n",
    " \n",
    "- The tree starts at the **root node**, which contains the full dataset.\n",
    "- At each node, the algorithm selects the **best feature and threshold** to split the data into two or more branches. The goal is to maximize information gain (in classification) or reduce variance (in regression). For regression, the model picks the feature so that the resulting tree has the **lowest RMSE**. For classification, the model picks the feature that reduces the **Gini index** (from 0 to 0.5 -> when 0, the node is pure).\n",
    "- This splitting process continues recursively until a stopping condition is met (e.g., max depth reached, or nodes are pure).\n",
    "- The final output is a leaf node, which provides the prediction:\n",
    "    - A class label in classification tasks,\n",
    "    - A numerical value in regression tasks.\n",
    "- Decision trees are not sensitive to the scale of the input features, so standardisation/normalisation \n",
    "is not required, unlike for KNN, logistic regression, linear regression, KMeans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_range = list(range(1,200))\n",
    "testing_error=[]\n",
    "training_error=[]\n",
    "\n",
    "for depth in max_depth_range:\n",
    "    treeclf = DecisionTreeClassifier(max_depth=depth, random_state=52)\n",
    "    treeclf.fit(X_train, y_train)\n",
    "    y_pred_class = treeclf.predict(X_test)\n",
    "    testing_accuracy=metrics.accuracy_score(y_test, y_pred_class)\n",
    "    testing_error.append(1-testing_accuracy)    \n",
    "    \n",
    "    y_pred_class = treeclf.predict(X_train)\n",
    "    training_accuracy=metrics.accuracy_score(y_train, y_pred_class)\n",
    "    training_error.append(1-training_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "treeclf_error = pd.DataFrame(list(zip(max_depth_range, training_error, testing_error)), columns=[\"max_length\",\"training_error\",\"testing_error\"])\n",
    "treeclf_error.sort_values(\"testing_error\")\n",
    "\n",
    "#max_lenght=7 leads to the lowest testing error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "treeclf = DecisionTreeClassifier(random_state=1, max_depth=7)\n",
    "treeclf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = treeclf.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(f'Test accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gini importance (impurity reduction): Suicidal Thoughts, Academic Pressure and Financial Stress.\n",
    "pd.DataFrame({'feature':X.columns, 'importance':treeclf.feature_importances_}).sort_values(\"importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_graphviz(treeclf, out_file='Decision_Tree', feature_names=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Random Forest is a supervised machine learning algorithm that consists of a collection (or “ensemble”) of many individual decision trees, typically trained using a method called bagging (each tree is trained on a randomly drawn subset of the training data, to increase diversity). It is used for both classification and regression tasks and is known for its accuracy, robustness, and ability to handle large datasets with high dimensionality.\n",
    "\n",
    "The idea behind a random forest is **to reduce the risk of overfitting** that is often associated with a single decision tree, while maintaining high predictive performance. This is achieved by building many decision trees during training and combining their outputs to make a final prediction:\n",
    "- For **classification**, it predicts the class that is the majority vote among all trees.\n",
    "- For **regression**, it predicts the average of the outputs from all trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1:\n",
    "rf_model = RandomForestClassifier(n_estimators=300, max_depth=10,random_state=52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 2: checking the best estimator\n",
    "n_estimator_range = range(10, 300, 10)\n",
    "mean_scores = []\n",
    "\n",
    "for n in n_estimator_range:\n",
    "    rf = RandomForestClassifier(n_estimators=n, random_state=52)\n",
    "    scores = cross_val_score(rf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    mean_scores.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(n_estimator_range, mean_scores);\n",
    "plt.xlabel('n_estimators');\n",
    "plt.ylabel('Cross-Validated Accuracy');\n",
    "plt.title('Choosing n_estimators');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 3: fitting the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf=rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#step 4: computing accuracy, metrics, confusion matrix.\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_rf))\n",
    "print(\"\\nClassification Report:\\n\", metrics.classification_report(y_test, y_pred_rf))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2: what are the most important predictors of depression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#feature importance: Suicidal Thoughts, Academic Pressure, CGPA, Age, Financial Stress\n",
    "\n",
    "#It gives a relative ranking of the predictors based on how often and how effectively they are used \n",
    "#to split the data across all trees in the forest.\n",
    "feature_importance = pd.DataFrame({\"feature\": X_train.columns,\"importance\": rf_model.feature_importances_\n",
    "}).sort_values(by=\"importance\", ascending=False)\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using GridSearch to select the best parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\"max_depth\": [3, 5, 10, 20, 30], \"n_estimators\": [100, 150, 200, 250, 300]}\n",
    "search = GridSearchCV(RandomForestClassifier(), param_grid=params, cv=5)\n",
    "search.fit(X_train, y_train)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *I WANT TO EXAMINE FALSE NEGATIVES: PEOPLE THAT ARE DEPRESSED BUT CLASSIFIED AS NOT DEPRESSED*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Machines (XGBoost, LightGBM, CatBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost\n",
    "\n",
    "XGBoost, short for eXtreme Gradient Boosting, is an open-source software library that provides an efficient and scalable implementation of gradient boosted decision trees. Gradient boosting is a machine learning technique that builds a strong predictive model by combining multiple \"weak\" models, typically decision trees, sequentially. Each new model attempts to correct the errors made by the preceding models, iteratively minimizing a loss function. XGBoost involves three main components: a loss function to be minimized, a weak learner to make predictions, and an additive model to add weak learners to minimize the loss function\n",
    "\n",
    "https://medium.com/@weidagang/essential-python-for-machine-learning-xgboost-4b662cf19fcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5943d1bfe3f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Using cached xgboost-2.1.4.tar.gz (1.1 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mPreparing metadata \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[63 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m INFO:xgboost.packager.build_wheel:Parsed build configuration: {'hide_cxx_symbols': True, 'use_openmp': True, 'use_cuda': False, 'use_nccl': False, 'use_dlopen_nccl': False, 'plugin_federated': False, 'plugin_rmm': False, 'use_system_libxgboost': False}\n",
      "  \u001b[31m   \u001b[0m INFO:xgboost.packager.build_wheel:Copying project files to temporary directory /var/folders/l9/y4n2vq0n2vj1zbf2642c48lw0000gn/T/tmpiewj88l_/whl_workspace\n",
      "  \u001b[31m   \u001b[0m INFO:xgboost.packager.build_wheel:Copying /private/var/folders/l9/y4n2vq0n2vj1zbf2642c48lw0000gn/T/pip-install-0nhsnb2t/xgboost_f61ae86c9912436d91ce194c1b8ea3a4/pyproject.toml -> /var/folders/l9/y4n2vq0n2vj1zbf2642c48lw0000gn/T/tmpiewj88l_/whl_workspace/pyproject.toml\n",
      "  \u001b[31m   \u001b[0m INFO:xgboost.packager.build_wheel:Copying /private/var/folders/l9/y4n2vq0n2vj1zbf2642c48lw0000gn/T/pip-install-0nhsnb2t/xgboost_f61ae86c9912436d91ce194c1b8ea3a4/hatch_build.py -> /var/folders/l9/y4n2vq0n2vj1zbf2642c48lw0000gn/T/tmpiewj88l_/whl_workspace/hatch_build.py\n",
      "  \u001b[31m   \u001b[0m INFO:xgboost.packager.build_wheel:Copying /private/var/folders/l9/y4n2vq0n2vj1zbf2642c48lw0000gn/T/pip-install-0nhsnb2t/xgboost_f61ae86c9912436d91ce194c1b8ea3a4/README.rst -> /var/folders/l9/y4n2vq0n2vj1zbf2642c48lw0000gn/T/tmpiewj88l_/whl_workspace/README.rst\n",
      "  \u001b[31m   \u001b[0m INFO:xgboost.packager.build_wheel:Copying /private/var/folders/l9/y4n2vq0n2vj1zbf2642c48lw0000gn/T/pip-install-0nhsnb2t/xgboost_f61ae86c9912436d91ce194c1b8ea3a4/xgboost -> /var/folders/l9/y4n2vq0n2vj1zbf2642c48lw0000gn/T/tmpiewj88l_/whl_workspace/xgboost\n",
      "  \u001b[31m   \u001b[0m INFO:xgboost.packager.build_libxgboost:Building libxgboost.dylib from the C++ source files in /private/var/folders/l9/y4n2vq0n2vj1zbf2642c48lw0000gn/T/pip-install-0nhsnb2t/xgboost_f61ae86c9912436d91ce194c1b8ea3a4/cpp_src...\n",
      "  \u001b[31m   \u001b[0m INFO:xgboost.packager.build_libxgboost:CMake args: ['cmake', '/private/var/folders/l9/y4n2vq0n2vj1zbf2642c48lw0000gn/T/pip-install-0nhsnb2t/xgboost_f61ae86c9912436d91ce194c1b8ea3a4/cpp_src', '-GUnix Makefiles', '-DKEEP_BUILD_ARTIFACTS_IN_BINARY_DIR=ON', '-DHIDE_CXX_SYMBOLS=ON', '-DUSE_OPENMP=ON', '-DUSE_CUDA=OFF', '-DUSE_NCCL=OFF', '-DUSE_DLOPEN_NCCL=OFF', '-DPLUGIN_FEDERATED=OFF', '-DPLUGIN_RMM=OFF']\n",
      "  \u001b[31m   \u001b[0m -- The CXX compiler identification is AppleClang 10.0.0.10001044\n",
      "  \u001b[31m   \u001b[0m -- The C compiler identification is AppleClang 10.0.0.10001044\n",
      "  \u001b[31m   \u001b[0m -- Detecting CXX compiler ABI info\n",
      "  \u001b[31m   \u001b[0m -- Detecting CXX compiler ABI info - done\n",
      "  \u001b[31m   \u001b[0m -- Check for working CXX compiler: /Library/Developer/CommandLineTools/usr/bin/c++ - skipped\n",
      "  \u001b[31m   \u001b[0m -- Detecting CXX compile features\n",
      "  \u001b[31m   \u001b[0m -- Detecting CXX compile features - done\n",
      "  \u001b[31m   \u001b[0m -- Detecting C compiler ABI info\n",
      "  \u001b[31m   \u001b[0m -- Detecting C compiler ABI info - done\n",
      "  \u001b[31m   \u001b[0m -- Check for working C compiler: /Library/Developer/CommandLineTools/usr/bin/cc - skipped\n",
      "  \u001b[31m   \u001b[0m -- Detecting C compile features\n",
      "  \u001b[31m   \u001b[0m -- Detecting C compile features - done\n",
      "  \u001b[31m   \u001b[0m -- CMake version 3.30.4\n",
      "  \u001b[31m   \u001b[0m CMake Error at CMakeLists.txt:35 (message):\n",
      "  \u001b[31m   \u001b[0m   Need Xcode 11.0 (AppleClang 11.0) or newer to build XGBoost\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m -- Configuring incomplete, errors occurred!\n",
      "  \u001b[31m   \u001b[0m INFO:xgboost.packager.build_libxgboost:Failed to build with OpenMP. Exception: Command '['cmake', '/private/var/folders/l9/y4n2vq0n2vj1zbf2642c48lw0000gn/T/pip-install-0nhsnb2t/xgboost_f61ae86c9912436d91ce194c1b8ea3a4/cpp_src', '-GUnix Makefiles', '-DKEEP_BUILD_ARTIFACTS_IN_BINARY_DIR=ON', '-DHIDE_CXX_SYMBOLS=ON', '-DUSE_OPENMP=ON', '-DUSE_CUDA=OFF', '-DUSE_NCCL=OFF', '-DUSE_DLOPEN_NCCL=OFF', '-DPLUGIN_FEDERATED=OFF', '-DPLUGIN_RMM=OFF']' returned non-zero exit status 1.\n",
      "  \u001b[31m   \u001b[0m INFO:xgboost.packager.build_libxgboost:CMake args: ['cmake', '/private/var/folders/l9/y4n2vq0n2vj1zbf2642c48lw0000gn/T/pip-install-0nhsnb2t/xgboost_f61ae86c9912436d91ce194c1b8ea3a4/cpp_src', '-GUnix Makefiles', '-DKEEP_BUILD_ARTIFACTS_IN_BINARY_DIR=ON', '-DHIDE_CXX_SYMBOLS=ON', '-DUSE_OPENMP=OFF', '-DUSE_CUDA=OFF', '-DUSE_NCCL=OFF', '-DUSE_DLOPEN_NCCL=OFF', '-DPLUGIN_FEDERATED=OFF', '-DPLUGIN_RMM=OFF']\n",
      "  \u001b[31m   \u001b[0m -- CMake version 3.30.4\n",
      "  \u001b[31m   \u001b[0m CMake Error at CMakeLists.txt:35 (message):\n",
      "  \u001b[31m   \u001b[0m   Need Xcode 11.0 (AppleClang 11.0) or newer to build XGBoost\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m -- Configuring incomplete, errors occurred!\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/l9/y4n2vq0n2vj1zbf2642c48lw0000gn/T/pip-install-0nhsnb2t/xgboost_f61ae86c9912436d91ce194c1b8ea3a4/packager/nativelib.py\", line 100, in build_libxgboost\n",
      "  \u001b[31m   \u001b[0m     _build(generator=generator)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/l9/y4n2vq0n2vj1zbf2642c48lw0000gn/T/pip-install-0nhsnb2t/xgboost_f61ae86c9912436d91ce194c1b8ea3a4/packager/nativelib.py\", line 57, in _build\n",
      "  \u001b[31m   \u001b[0m     subprocess.check_call(cmake_cmd, cwd=build_dir)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/anaconda3/lib/python3.8/subprocess.py\", line 364, in check_call\n",
      "  \u001b[31m   \u001b[0m     raise CalledProcessError(retcode, cmd)\n",
      "  \u001b[31m   \u001b[0m subprocess.CalledProcessError: Command '['cmake', '/private/var/folders/l9/y4n2vq0n2vj1zbf2642c48lw0000gn/T/pip-install-0nhsnb2t/xgboost_f61ae86c9912436d91ce194c1b8ea3a4/cpp_src', '-GUnix Makefiles', '-DKEEP_BUILD_ARTIFACTS_IN_BINARY_DIR=ON', '-DHIDE_CXX_SYMBOLS=ON', '-DUSE_OPENMP=ON', '-DUSE_CUDA=OFF', '-DUSE_NCCL=OFF', '-DUSE_DLOPEN_NCCL=OFF', '-DPLUGIN_FEDERATED=OFF', '-DPLUGIN_RMM=OFF']' returned non-zero exit status 1.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m During handling of the above exception, another exception occurred:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/anaconda3/lib/python3.8/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 389, in <module>\n",
      "  \u001b[31m   \u001b[0m     main()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/anaconda3/lib/python3.8/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 373, in main\n",
      "  \u001b[31m   \u001b[0m     json_out[\"return_val\"] = hook(**hook_input[\"kwargs\"])\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/anaconda3/lib/python3.8/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 178, in prepare_metadata_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     whl_basename = backend.build_wheel(metadata_directory, config_settings)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/l9/y4n2vq0n2vj1zbf2642c48lw0000gn/T/pip-install-0nhsnb2t/xgboost_f61ae86c9912436d91ce194c1b8ea3a4/packager/pep517.py\", line 80, in build_wheel\n",
      "  \u001b[31m   \u001b[0m     libxgboost = locate_or_build_libxgboost(\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/l9/y4n2vq0n2vj1zbf2642c48lw0000gn/T/pip-install-0nhsnb2t/xgboost_f61ae86c9912436d91ce194c1b8ea3a4/packager/nativelib.py\", line 171, in locate_or_build_libxgboost\n",
      "  \u001b[31m   \u001b[0m     return build_libxgboost(cpp_src_dir, build_dir=build_dir, build_config=build_config)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/l9/y4n2vq0n2vj1zbf2642c48lw0000gn/T/pip-install-0nhsnb2t/xgboost_f61ae86c9912436d91ce194c1b8ea3a4/packager/nativelib.py\", line 104, in build_libxgboost\n",
      "  \u001b[31m   \u001b[0m     _build(generator=generator)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/l9/y4n2vq0n2vj1zbf2642c48lw0000gn/T/pip-install-0nhsnb2t/xgboost_f61ae86c9912436d91ce194c1b8ea3a4/packager/nativelib.py\", line 57, in _build\n",
      "  \u001b[31m   \u001b[0m     subprocess.check_call(cmake_cmd, cwd=build_dir)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/anaconda3/lib/python3.8/subprocess.py\", line 364, in check_call\n",
      "  \u001b[31m   \u001b[0m     raise CalledProcessError(retcode, cmd)\n",
      "  \u001b[31m   \u001b[0m subprocess.CalledProcessError: Command '['cmake', '/private/var/folders/l9/y4n2vq0n2vj1zbf2642c48lw0000gn/T/pip-install-0nhsnb2t/xgboost_f61ae86c9912436d91ce194c1b8ea3a4/cpp_src', '-GUnix Makefiles', '-DKEEP_BUILD_ARTIFACTS_IN_BINARY_DIR=ON', '-DHIDE_CXX_SYMBOLS=ON', '-DUSE_OPENMP=OFF', '-DUSE_CUDA=OFF', '-DUSE_NCCL=OFF', '-DUSE_DLOPEN_NCCL=OFF', '-DPLUGIN_FEDERATED=OFF', '-DPLUGIN_RMM=OFF']' returned non-zero exit status 1.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "print(xgb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!conda list xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip uninstall -y xgboost\n",
    "!{sys.executable} -m pip uninstall -y libxgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --force-reinstall --no-cache-dir xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no need to scale the model\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=10)#HOW DO I CHANGE NUMBER OF ESTIMATORS??\n",
    "pipeline_xgb.fit(X_train, y_train)\n",
    "predictions_xgb = pipeline_xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "accuracy_xgb = accuracy_score(y_test, predictions_xgb)\n",
    "print('y_test:', y_test)\n",
    "print('predictions:', predictions)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importance = model.feature_importances_\n",
    "\n",
    "# Plotting feature importance\n",
    "plt.barh(iris.feature_names, feature_importance)\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Visualizing Important Features with XGBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter tuning https://www.youtube.com/watch?v=wqnwm15bg7A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Clustering - see if certain groups of people are more prone to depression - then we compare clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=3, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=3, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(n_clusters=3, random_state=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km = KMeans(n_clusters=3, random_state=1)\n",
    "km.fit(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Academic Pressure</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Study Satisfaction</th>\n",
       "      <th>Work_study_hours</th>\n",
       "      <th>Financial Stress</th>\n",
       "      <th>Gender_1</th>\n",
       "      <th>Sleep Duration_1</th>\n",
       "      <th>Sleep Duration_2</th>\n",
       "      <th>Sleep Duration_3</th>\n",
       "      <th>Sleep Duration_4</th>\n",
       "      <th>Dietary Habits_1</th>\n",
       "      <th>Dietary Habits_2</th>\n",
       "      <th>Dietary Habits_3</th>\n",
       "      <th>Suicidal Thoughts_1</th>\n",
       "      <th>Family History_1</th>\n",
       "      <th>cluster_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.97</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.90</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.59</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27896</th>\n",
       "      <td>27</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27897</th>\n",
       "      <td>27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.40</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27898</th>\n",
       "      <td>31</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.61</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27899</th>\n",
       "      <td>18</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.88</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27900</th>\n",
       "      <td>27</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27901 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age  Academic Pressure  CGPA  Study Satisfaction  Work_study_hours  \\\n",
       "0       33                5.0  8.97                 2.0               3.0   \n",
       "1       24                2.0  5.90                 5.0               3.0   \n",
       "2       31                3.0  7.03                 5.0               9.0   \n",
       "3       28                3.0  5.59                 2.0               4.0   \n",
       "4       25                4.0  8.13                 3.0               1.0   \n",
       "...    ...                ...   ...                 ...               ...   \n",
       "27896   27                5.0  5.75                 5.0               7.0   \n",
       "27897   27                2.0  9.40                 3.0               0.0   \n",
       "27898   31                3.0  6.61                 4.0              12.0   \n",
       "27899   18                5.0  6.88                 2.0              10.0   \n",
       "27900   27                4.0  9.24                 1.0               2.0   \n",
       "\n",
       "       Financial Stress  Gender_1  Sleep Duration_1  Sleep Duration_2  \\\n",
       "0                   1.0     False             False             False   \n",
       "1                   2.0      True             False             False   \n",
       "2                   1.0     False              True             False   \n",
       "3                   5.0      True             False              True   \n",
       "4                   1.0      True             False             False   \n",
       "...                 ...       ...               ...               ...   \n",
       "27896               1.0      True             False             False   \n",
       "27897               3.0     False              True             False   \n",
       "27898               2.0     False             False             False   \n",
       "27899               5.0      True              True             False   \n",
       "27900               3.0     False              True             False   \n",
       "\n",
       "       Sleep Duration_3  Sleep Duration_4  Dietary Habits_1  Dietary Habits_2  \\\n",
       "0                 False             False             False             False   \n",
       "1                 False             False              True             False   \n",
       "2                 False             False             False             False   \n",
       "3                 False             False              True             False   \n",
       "4                 False             False              True             False   \n",
       "...                 ...               ...               ...               ...   \n",
       "27896             False             False             False              True   \n",
       "27897             False             False             False             False   \n",
       "27898             False             False             False              True   \n",
       "27899             False             False             False             False   \n",
       "27900             False             False             False             False   \n",
       "\n",
       "       Dietary Habits_3  Suicidal Thoughts_1  Family History_1  cluster_scaled  \n",
       "0                 False                 True             False               0  \n",
       "1                 False                False              True               0  \n",
       "2                 False                False              True               1  \n",
       "3                 False                 True              True               0  \n",
       "4                 False                 True             False               0  \n",
       "...                 ...                  ...               ...             ...  \n",
       "27896             False                 True              True               0  \n",
       "27897             False                False              True               1  \n",
       "27898             False                False             False               0  \n",
       "27899             False                 True             False               1  \n",
       "27900             False                 True              True               1  \n",
       "\n",
       "[27901 rows x 17 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[\"cluster_scaled\"] = km.labels_\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "inertia_list = []\n",
    "k_list = []\n",
    "\n",
    "for k in range(1, 10):\n",
    "    km = KMeans(n_clusters=k, random_state=1)\n",
    "    km.fit(X)\n",
    "    k_list.append(k)\n",
    "    inertia_list.append(km.inertia_)\n",
    "    \n",
    "plt.plot(k_list, inertia_list)\n",
    "plt.xlabel(\"Cluster Number\")\n",
    "plt.ylabel(\"Inertia\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 2, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km = KMeans(n_clusters=4, random_state=1)\n",
    "km.fit(X_scaled)\n",
    "km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.56619340e-03, -6.67704581e-02, -3.27753745e-02,\n",
       "         2.29071098e-02, -8.40217634e-02, -1.94029643e-02,\n",
       "        -1.30444311e-02, -6.51286700e-01, -5.97814881e-01,\n",
       "         1.90166077e+00, -2.54077673e-02, -2.46004389e-03,\n",
       "         2.09065170e-03, -1.27633930e-02, -1.13850355e-01,\n",
       "        -9.62149035e-03],\n",
       "       [ 4.79328305e-02, -4.65023619e-02,  1.04706507e-02,\n",
       "         1.19604820e-03,  3.58772497e-03, -6.36987937e-02,\n",
       "         4.84599750e-02,  1.81094942e-01,  1.48435624e-01,\n",
       "        -5.25856143e-01, -2.54077673e-02,  4.36183135e-01,\n",
       "        -7.65980789e-01,  1.77816312e-02, -4.17903039e-02,\n",
       "        -5.27317171e-04],\n",
       "       [-7.60849446e-02,  1.29352135e-01,  6.77294266e-03,\n",
       "        -1.94761334e-02,  5.70478425e-02,  1.23995528e-01,\n",
       "        -7.31997178e-02,  1.80248083e-01,  1.95816415e-01,\n",
       "        -5.25856143e-01, -2.54077673e-02, -7.42818790e-01,\n",
       "         1.30551577e+00, -2.07431234e-02,  1.56719886e-01,\n",
       "         8.28424718e-03],\n",
       "       [ 3.08022097e-01,  1.84250409e-02, -4.11704624e-02,\n",
       "         1.22894039e-01, -1.02278653e-01, -3.29350819e-01,\n",
       "         1.15197174e-01, -6.51286700e-01, -5.97814881e-01,\n",
       "        -5.25856143e-01,  3.93580431e+01,  6.95864863e-02,\n",
       "         1.54684348e-01, -2.07431234e-02, -4.50124140e-02,\n",
       "        -7.90741011e-02]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers=km.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agglomeration Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction (PCA, t-SNE, UMAP). Goal: visualise high-dimensional data in 2D or 3D. Used to understand the structure of our data, or visualise clusters and how they relate to depression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
